{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database from\n",
    "https://www.kaggle.com/datasets/andrewmvd/ocular-disease-recognition-odir5k/data?select=full_df.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in ./.venv/lib/python3.12/site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./.venv/lib/python3.12/site-packages (from imbalanced-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./.venv/lib/python3.12/site-packages (from imbalanced-learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in ./.venv/lib/python3.12/site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.venv/lib/python3.12/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.12/site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.image import resize\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.metrics import  Recall, CategoricalAccuracy\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import concatenate as concat\n",
    "from scipy.stats import entropy\n",
    "import os\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from helpers.help import *\n",
    "from helpers.helptf import *\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset\n",
    "Reading both eyes while filtering the intended diseases\n",
    "and including the augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- LEFT ----\n",
      "191\n",
      "85\n",
      "4587\n",
      "---- RIGHT ----\n",
      "191\n",
      "80\n",
      "4511\n",
      "---- AUGMENTED ----\n",
      "1152\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('hr-dataset/full_df.csv')\n",
    "\n",
    "#Left eye\n",
    "# get the diagnostic of hypertensive retinopathy\n",
    "ds_hr_left = df[df['Left-Diagnostic Keywords'].str.contains('hypertensive retinopathy', na=False)]\n",
    "# get the diagnostic of diabetic retinopathy\n",
    "ds_dr_left = df[df['Left-Diagnostic Keywords'].str.contains('diabetic retinopathy', na=False)]\n",
    "# get the diagnostic for no rethinopathy\n",
    "ds_nr_left = df[~df['Left-Diagnostic Keywords'].str.contains('retinopathy', na=False)]\n",
    "# get the diagnostic of normal fundus\n",
    "# ds_normal_left = df[df['Left-Diagnostic Keywords'] == 'normal fundus']\n",
    "\n",
    "\n",
    "#Right eye\n",
    "# get the diagnostic of hypertensive retinopathy\n",
    "ds_hr_right = df[df['Right-Diagnostic Keywords'].str.contains('hypertensive retinopathy', na=False)]\n",
    "# get the diagnostic of diabetic retinopathy\n",
    "ds_dr_right = df[df['Right-Diagnostic Keywords'].str.contains('diabetic retinopathy', na=False)]\n",
    "# get the diagnostic for no retinopathy\n",
    "ds_nr_right = df[~df['Right-Diagnostic Keywords'].str.contains('retinopathy', na=False)]\n",
    "# get the diagnostic of normal fundus\n",
    "# ds_normal_right = df[df['Right-Diagnostic Keywords'] == 'normal fundus']\n",
    "\n",
    "\n",
    "\n",
    "# Specific dataframe\n",
    "# Left eye\n",
    "df_hr_left = ds_hr_left[['Left-Diagnostic Keywords', 'Left-Fundus']]\n",
    "df_dr_left = ds_dr_left[['Left-Diagnostic Keywords', 'Left-Fundus']]\n",
    "df_nr_left = ds_nr_left[['Left-Diagnostic Keywords', 'Left-Fundus']]\n",
    "\n",
    "# Right eye\n",
    "df_hr_right = ds_hr_right[['Right-Diagnostic Keywords', 'Right-Fundus']]\n",
    "df_dr_right = ds_dr_right[['Right-Diagnostic Keywords', 'Right-Fundus']]\n",
    "df_nr_right = ds_nr_right[['Right-Diagnostic Keywords', 'Right-Fundus']]\n",
    "\n",
    "\n",
    "# Droping class\n",
    "# Left eye\n",
    "df_hr_left = df_hr_left.drop('Left-Diagnostic Keywords', axis=1)\n",
    "df_dr_left = df_dr_left.drop('Left-Diagnostic Keywords', axis=1)\n",
    "df_nr_left = df_nr_left.drop('Left-Diagnostic Keywords', axis=1)\n",
    "# Right eye\n",
    "df_hr_right = df_hr_right.drop('Right-Diagnostic Keywords', axis=1)\n",
    "df_dr_right = df_dr_right.drop('Right-Diagnostic Keywords', axis=1)\n",
    "df_nr_right = df_nr_right.drop('Right-Diagnostic Keywords', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Get augmented images\n",
    "path = os.path.join(os.getcwd(),'hr-dataset/augmented_images')\n",
    "list_hr_augmented = []\n",
    "list_dr_augmented = []\n",
    "\n",
    "for file in os.listdir(path + '/hr'):\n",
    "    if file != '.DS_Store':\n",
    "        list_hr_augmented.append(file)\n",
    "    \n",
    "for file in os.listdir(path + '/dr'):\n",
    "    if file != '.DS_Store':\n",
    "        list_dr_augmented.append(file)\n",
    "    \n",
    "df_hr_augmented = pd.DataFrame(list_hr_augmented, columns = ['Left-Fundus'])\n",
    "df_dr_augmented = pd.DataFrame(list_dr_augmented, columns = ['Left-Fundus'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"---- LEFT ----\")\n",
    "print(df_hr_left.shape[0])\n",
    "print(df_dr_left.shape[0])\n",
    "print(df_nr_left.shape[0])\n",
    "print(\"---- RIGHT ----\")\n",
    "print(df_hr_right.shape[0])\n",
    "print(df_dr_right.shape[0])\n",
    "print(df_nr_right.shape[0])\n",
    "print(\"---- AUGMENTED ----\")\n",
    "print(df_hr_augmented.shape[0])\n",
    "print(df_dr_augmented.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the undersampling of HR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "645\n",
      "720\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# join left and right eye sets\n",
    "df_hr = pd.concat([df_hr_left, df_hr_right, df_hr_augmented ])\n",
    "df_dr = pd.concat([df_dr_left, df_dr_right, df_dr_augmented ])\n",
    "df_nr = pd.concat([df_nr_left, df_nr_right])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Since the minimum value of samples is from DR: 645 (480+164), we will undersample the rest\n",
    "    to balance the dataset\n",
    "\"\"\"\n",
    "\n",
    "df_hr_downsampled = resample(df_hr, replace=False, n_samples=1200, random_state=10) # full + DA (1200)\n",
    "df_dr_downsampled = resample(df_dr, replace=False, n_samples=645, random_state=10) # full\n",
    "df_nr_downsampled = resample(df_nr, replace=False, n_samples=720, random_state=10) # randomly selected from the dataset (720)\n",
    "\n",
    "print(df_hr_downsampled.shape[0])\n",
    "print(df_dr_downsampled.shape[0])\n",
    "print(df_nr_downsampled.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2538"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare dataset paths\n",
    "path = os.path.join(os.getcwd(),'hr-dataset/preprocessed_images')\n",
    "pathHR = os.path.join(os.getcwd(),'hr-dataset/augmented_images/hr')\n",
    "pathDB = os.path.join(os.getcwd(),'hr-dataset/augmented_images/dr')\n",
    "\n",
    "# 0 - No Diabetic or Hipertensive Retinopathy\n",
    "# 1 - Diabetic Retinopathy\n",
    "# 2 - Hipertensive Retinopathy\n",
    "\n",
    "array = []\n",
    "detailPath = \"\"\n",
    "\n",
    "# get HR images\n",
    "for index, row in df_hr_downsampled.iterrows():\n",
    "    if type(row['Left-Fundus']) != float:\n",
    "        detailPath = os.path.join(path,row['Left-Fundus'])\n",
    "        detailPathHR = os.path.join(pathHR,row['Left-Fundus'])\n",
    "    else:\n",
    "        detailPath = os.path.join(path,row['Right-Fundus'])\n",
    "    if(os.path.exists(detailPath)):\n",
    "        array.append([detailPath,2])\n",
    "    elif(os.path.exists(detailPathHR)):\n",
    "        array.append([detailPathHR,2])\n",
    "\n",
    "\n",
    "\n",
    "# get DR images\n",
    "for index, row in df_dr_downsampled.iterrows():\n",
    "    if type(row['Left-Fundus']) != float:\n",
    "        detailPath = os.path.join(path,row['Left-Fundus'])\n",
    "        detailPathDR = os.path.join(pathDB,row['Left-Fundus'])\n",
    "    else:\n",
    "        detailPath = os.path.join(path,row['Right-Fundus'])\n",
    "    if(os.path.exists(detailPath)):\n",
    "        array.append([detailPath,1])\n",
    "    elif(os.path.exists(detailPathDR)):\n",
    "        array.append([detailPathDR,1])\n",
    "\n",
    "\n",
    "# get no rethinopaty images\n",
    "for index, row in df_nr_downsampled.iterrows():\n",
    "    if type(row['Left-Fundus']) != float:\n",
    "        detailPath = os.path.join(path,row['Left-Fundus'])\n",
    "    else:\n",
    "        detailPath = os.path.join(path,row['Right-Fundus'])\n",
    "    if(os.path.exists(detailPath)):\n",
    "        array.append([detailPath,0])\n",
    "\n",
    "\n",
    "    \n",
    "# transforms the array into nparray\n",
    "dataset=np.array(array)\n",
    "\n",
    "np.size(dataset,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data ready\n",
    "Separating 10% of the data for test and 11% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=dataset[::,0],dataset[::,1]\n",
    "y = y.astype(int)\n",
    "\n",
    "#One hot encode the labels\n",
    "y = to_categorical(y)\n",
    "\n",
    "\n",
    "#Shuffle the dataset (to make a unbiased model)\n",
    "p = np.random.permutation(len(X))\n",
    "X,y = X[p], y[p]\n",
    "\n",
    "#Strip off 10% samples for hold out test set\n",
    "test_idxs = np.random.choice(len(X), size=int(0.1*len(X)), replace=False, p=None)\n",
    "x_test, y_test = X[test_idxs],y[test_idxs]\n",
    "\n",
    "#Delete the test set samples from X,y \n",
    "X = np.delete(X, test_idxs)\n",
    "y = np.delete(y, test_idxs, axis = 0)\n",
    "\n",
    "#usual train-val split. We use 11% \n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in Training set: 1828\n",
      "Samples in Validation set: 457\n",
      "Samples in Test set: 253\n"
     ]
    }
   ],
   "source": [
    "print(f\"Samples in Training set: {x_train.shape[0]}\")\n",
    "print(f\"Samples in Validation set: {x_val.shape[0]}\")\n",
    "print(f\"Samples in Test set: {x_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.]]), array([875, 460, 493]))\n",
      "(array([[0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.]]), array([109,  70,  74]))\n",
      "(array([[0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.]]), array([216, 110, 131]))\n"
     ]
    }
   ],
   "source": [
    "# Check if imbalance\n",
    "for i in [y_train, y_test, y_val]:\n",
    "    print(np.unique(i, return_counts = True, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepares Data for the model\n",
    "Create batches of 32 for validation and testing sets\n",
    "Batch of 16 for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 3), dtype=tf.float64, name=None))>\n",
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 3), dtype=tf.float64, name=None))>\n",
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 3), dtype=tf.float64, name=None))>\n",
      "(224, 224, 3)\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "val_dataset=build_dataset(x_val,y_val,repeat=False,batch=32)\n",
    "test_dataset=build_dataset(x_test,y_test,repeat=False,batch=32)\n",
    "\n",
    "BATCH_SIZE=16\n",
    "STEPS_PER_EPOCH=len(x_train)/BATCH_SIZE\n",
    "\n",
    "train_dataset=build_dataset(x_train,y_train,batch=BATCH_SIZE)\n",
    "\n",
    "# input shape for the model\n",
    "input_shape=train_dataset.element_spec[0].shape[1:]\n",
    "\n",
    "\n",
    "print(train_dataset)\n",
    "print(val_dataset)\n",
    "print(test_dataset)\n",
    "\n",
    "input_shape=train_dataset.element_spec[0].shape[1:]\n",
    "print(input_shape)\n",
    "\n",
    "for batch in train_dataset.take(1):\n",
    "    features, labels = batch  # Unpack the tuple\n",
    "    print(features.shape[0])  # Number of elements in the batch\n",
    "    print(labels.shape[0])  # Number of elements in the batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m53\u001b[0m, \u001b[38;5;34m53\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m53\u001b[0m, \u001b[38;5;34m53\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m11,075,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,510,472</span> (127.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,510,472\u001b[0m (127.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,922</span> (42.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,169,922\u001b[0m (42.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,339,846</span> (85.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m22,339,846\u001b[0m (85.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dr_model = load_model('model/model_al.keras')\n",
    "\n",
    "dr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the transfer learning pre-built function\n",
    "Will cut the 10 upper layers, and 3 output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After layer 0 (conv2d), shape: (None, 224, 224, 32)\n",
      "After layer 1 (batch_normalization), shape: (None, 224, 224, 32)\n",
      "After layer 2 (max_pooling2d), shape: (None, 112, 112, 32)\n",
      "After layer 3 (dropout), shape: (None, 112, 112, 32)\n",
      "After layer 4 (conv2d_1), shape: (None, 110, 110, 64)\n",
      "After layer 5 (batch_normalization_1), shape: (None, 110, 110, 64)\n",
      "After layer 6 (max_pooling2d_1), shape: (None, 55, 55, 64)\n"
     ]
    }
   ],
   "source": [
    "# classes: {\"no_rethinopathy\", \"dr\",\"hr\"}\n",
    "transfer_model = prep_translearn(model=dr_model, top_layers_to_cut=10, out_dim=3, learning_rate=0.0001) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_53\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_53\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ NEW_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ NEW_FLAT                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ NEW_Signature (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ NEW_Dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ NEW_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ NEW_input (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m110\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ NEW_FLAT                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ NEW_Signature (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ NEW_Dropout (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ NEW_output (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,483</span> (111.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,483\u001b[0m (111.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,291</span> (110.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,291\u001b[0m (110.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transfer_model.compile(\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        optimizer = Adam(),\n",
    "        metrics=[CategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the model with the lowest validation Loss\n",
    "checkpoint=ModelCheckpoint(filepath='model/model_transferlearning_aug.keras',\n",
    "                           monitor='val_loss',save_best_only=True,verbose=1)\n",
    "\n",
    "# logs the training progress to a CSV\n",
    "csv_logger=keras.callbacks.CSVLogger('logger/trainlog_transferlearning_aug.csv',\n",
    "                                     separator=',',append=False)\n",
    "\n",
    "# defines a early stop if in 10 epoches the validation loss dont improve\n",
    "early_stopper=keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                            min_delta=0.001,\n",
    "                                            restore_best_weights=True,\n",
    "                                            patience=10)\n",
    "\n",
    "callbacks_list=[checkpoint,early_stopper,csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466ms/step - categorical_accuracy: 0.4631 - loss: 1.0231\n",
      "Epoch 1: val_loss improved from inf to 1.12522, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 491ms/step - categorical_accuracy: 0.4635 - loss: 1.0226 - val_categorical_accuracy: 0.5339 - val_loss: 1.1252\n",
      "Epoch 2/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - categorical_accuracy: 0.5537 - loss: 0.9040\n",
      "Epoch 2: val_loss improved from 1.12522 to 0.87263, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 454ms/step - categorical_accuracy: 0.5537 - loss: 0.9040 - val_categorical_accuracy: 0.5930 - val_loss: 0.8726\n",
      "Epoch 3/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - categorical_accuracy: 0.5550 - loss: 0.8798\n",
      "Epoch 3: val_loss did not improve from 0.87263\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 366ms/step - categorical_accuracy: 0.5550 - loss: 0.8797 - val_categorical_accuracy: 0.4617 - val_loss: 1.3844\n",
      "Epoch 4/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - categorical_accuracy: 0.6110 - loss: 0.8364\n",
      "Epoch 4: val_loss did not improve from 0.87263\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 368ms/step - categorical_accuracy: 0.6109 - loss: 0.8366 - val_categorical_accuracy: 0.4814 - val_loss: 1.0381\n",
      "Epoch 5/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - categorical_accuracy: 0.6041 - loss: 0.8283\n",
      "Epoch 5: val_loss did not improve from 0.87263\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 369ms/step - categorical_accuracy: 0.6041 - loss: 0.8284 - val_categorical_accuracy: 0.4814 - val_loss: 1.4284\n",
      "Epoch 6/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - categorical_accuracy: 0.5904 - loss: 0.8189\n",
      "Epoch 6: val_loss did not improve from 0.87263\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 368ms/step - categorical_accuracy: 0.5905 - loss: 0.8188 - val_categorical_accuracy: 0.5098 - val_loss: 1.3255\n",
      "Epoch 7/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - categorical_accuracy: 0.6223 - loss: 0.7912\n",
      "Epoch 7: val_loss did not improve from 0.87263\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 368ms/step - categorical_accuracy: 0.6222 - loss: 0.7912 - val_categorical_accuracy: 0.5689 - val_loss: 0.8755\n",
      "Epoch 8/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - categorical_accuracy: 0.6510 - loss: 0.7546\n",
      "Epoch 8: val_loss did not improve from 0.87263\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 371ms/step - categorical_accuracy: 0.6508 - loss: 0.7547 - val_categorical_accuracy: 0.5733 - val_loss: 0.8828\n",
      "Epoch 9/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - categorical_accuracy: 0.6403 - loss: 0.7657\n",
      "Epoch 9: val_loss did not improve from 0.87263\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 373ms/step - categorical_accuracy: 0.6404 - loss: 0.7657 - val_categorical_accuracy: 0.5449 - val_loss: 0.9145\n",
      "Epoch 10/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - categorical_accuracy: 0.6631 - loss: 0.7196\n",
      "Epoch 10: val_loss did not improve from 0.87263\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 375ms/step - categorical_accuracy: 0.6630 - loss: 0.7198 - val_categorical_accuracy: 0.5514 - val_loss: 0.9439\n",
      "Epoch 11/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - categorical_accuracy: 0.6561 - loss: 0.7413\n",
      "Epoch 11: val_loss improved from 0.87263 to 0.75880, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 372ms/step - categorical_accuracy: 0.6561 - loss: 0.7412 - val_categorical_accuracy: 0.6455 - val_loss: 0.7588\n",
      "Epoch 12/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - categorical_accuracy: 0.6756 - loss: 0.7005\n",
      "Epoch 12: val_loss improved from 0.75880 to 0.73873, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 377ms/step - categorical_accuracy: 0.6755 - loss: 0.7007 - val_categorical_accuracy: 0.6368 - val_loss: 0.7387\n",
      "Epoch 13/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - categorical_accuracy: 0.6434 - loss: 0.7316\n",
      "Epoch 13: val_loss improved from 0.73873 to 0.73555, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 380ms/step - categorical_accuracy: 0.6436 - loss: 0.7315 - val_categorical_accuracy: 0.6674 - val_loss: 0.7355\n",
      "Epoch 14/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - categorical_accuracy: 0.6634 - loss: 0.6934\n",
      "Epoch 14: val_loss did not improve from 0.73555\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 388ms/step - categorical_accuracy: 0.6635 - loss: 0.6935 - val_categorical_accuracy: 0.5339 - val_loss: 0.9630\n",
      "Epoch 15/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - categorical_accuracy: 0.6865 - loss: 0.6822\n",
      "Epoch 15: val_loss did not improve from 0.73555\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 432ms/step - categorical_accuracy: 0.6865 - loss: 0.6822 - val_categorical_accuracy: 0.6455 - val_loss: 0.7400\n",
      "Epoch 16/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - categorical_accuracy: 0.6821 - loss: 0.6871\n",
      "Epoch 16: val_loss improved from 0.73555 to 0.68370, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 441ms/step - categorical_accuracy: 0.6821 - loss: 0.6872 - val_categorical_accuracy: 0.7155 - val_loss: 0.6837\n",
      "Epoch 17/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - categorical_accuracy: 0.6801 - loss: 0.6606\n",
      "Epoch 17: val_loss improved from 0.68370 to 0.65772, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 437ms/step - categorical_accuracy: 0.6801 - loss: 0.6607 - val_categorical_accuracy: 0.6827 - val_loss: 0.6577\n",
      "Epoch 18/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - categorical_accuracy: 0.6983 - loss: 0.6688\n",
      "Epoch 18: val_loss did not improve from 0.65772\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 408ms/step - categorical_accuracy: 0.6982 - loss: 0.6689 - val_categorical_accuracy: 0.7177 - val_loss: 0.6941\n",
      "Epoch 19/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - categorical_accuracy: 0.6998 - loss: 0.6518\n",
      "Epoch 19: val_loss did not improve from 0.65772\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 408ms/step - categorical_accuracy: 0.6997 - loss: 0.6520 - val_categorical_accuracy: 0.6411 - val_loss: 0.7651\n",
      "Epoch 20/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - categorical_accuracy: 0.7081 - loss: 0.6530\n",
      "Epoch 20: val_loss did not improve from 0.65772\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 418ms/step - categorical_accuracy: 0.7080 - loss: 0.6531 - val_categorical_accuracy: 0.6937 - val_loss: 0.6944\n",
      "Epoch 21/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - categorical_accuracy: 0.7117 - loss: 0.6537\n",
      "Epoch 21: val_loss did not improve from 0.65772\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 409ms/step - categorical_accuracy: 0.7116 - loss: 0.6538 - val_categorical_accuracy: 0.7112 - val_loss: 0.6773\n",
      "Epoch 22/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - categorical_accuracy: 0.7005 - loss: 0.6396\n",
      "Epoch 22: val_loss improved from 0.65772 to 0.65260, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 409ms/step - categorical_accuracy: 0.7003 - loss: 0.6398 - val_categorical_accuracy: 0.7155 - val_loss: 0.6526\n",
      "Epoch 23/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - categorical_accuracy: 0.7011 - loss: 0.6426\n",
      "Epoch 23: val_loss improved from 0.65260 to 0.64524, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 433ms/step - categorical_accuracy: 0.7010 - loss: 0.6428 - val_categorical_accuracy: 0.7133 - val_loss: 0.6452\n",
      "Epoch 24/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - categorical_accuracy: 0.6882 - loss: 0.6479\n",
      "Epoch 24: val_loss did not improve from 0.64524\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 408ms/step - categorical_accuracy: 0.6884 - loss: 0.6478 - val_categorical_accuracy: 0.6893 - val_loss: 0.6677\n",
      "Epoch 25/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - categorical_accuracy: 0.7284 - loss: 0.6116\n",
      "Epoch 25: val_loss did not improve from 0.64524\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 427ms/step - categorical_accuracy: 0.7282 - loss: 0.6117 - val_categorical_accuracy: 0.6761 - val_loss: 0.7342\n",
      "Epoch 26/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - categorical_accuracy: 0.6920 - loss: 0.6583\n",
      "Epoch 26: val_loss improved from 0.64524 to 0.63795, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 395ms/step - categorical_accuracy: 0.6921 - loss: 0.6581 - val_categorical_accuracy: 0.7155 - val_loss: 0.6379\n",
      "Epoch 27/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - categorical_accuracy: 0.7120 - loss: 0.6277\n",
      "Epoch 27: val_loss did not improve from 0.63795\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 379ms/step - categorical_accuracy: 0.7120 - loss: 0.6277 - val_categorical_accuracy: 0.6740 - val_loss: 0.6530\n",
      "Epoch 28/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - categorical_accuracy: 0.7193 - loss: 0.6145\n",
      "Epoch 28: val_loss did not improve from 0.63795\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 384ms/step - categorical_accuracy: 0.7192 - loss: 0.6145 - val_categorical_accuracy: 0.6368 - val_loss: 0.7487\n",
      "Epoch 29/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - categorical_accuracy: 0.7044 - loss: 0.6116\n",
      "Epoch 29: val_loss did not improve from 0.63795\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 378ms/step - categorical_accuracy: 0.7045 - loss: 0.6116 - val_categorical_accuracy: 0.6083 - val_loss: 0.8627\n",
      "Epoch 30/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - categorical_accuracy: 0.7288 - loss: 0.5998\n",
      "Epoch 30: val_loss did not improve from 0.63795\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 380ms/step - categorical_accuracy: 0.7287 - loss: 0.5998 - val_categorical_accuracy: 0.7024 - val_loss: 0.6481\n",
      "Epoch 31/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - categorical_accuracy: 0.7081 - loss: 0.6247\n",
      "Epoch 31: val_loss did not improve from 0.63795\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 378ms/step - categorical_accuracy: 0.7082 - loss: 0.6244 - val_categorical_accuracy: 0.6718 - val_loss: 0.9134\n",
      "Epoch 32/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - categorical_accuracy: 0.7333 - loss: 0.5966\n",
      "Epoch 32: val_loss did not improve from 0.63795\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 378ms/step - categorical_accuracy: 0.7333 - loss: 0.5966 - val_categorical_accuracy: 0.6455 - val_loss: 0.8173\n",
      "Epoch 33/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - categorical_accuracy: 0.7213 - loss: 0.6134\n",
      "Epoch 33: val_loss did not improve from 0.63795\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 423ms/step - categorical_accuracy: 0.7212 - loss: 0.6134 - val_categorical_accuracy: 0.6521 - val_loss: 0.7096\n",
      "Epoch 34/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - categorical_accuracy: 0.7084 - loss: 0.6221\n",
      "Epoch 34: val_loss did not improve from 0.63795\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 430ms/step - categorical_accuracy: 0.7085 - loss: 0.6220 - val_categorical_accuracy: 0.6149 - val_loss: 0.9446\n",
      "Epoch 35/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - categorical_accuracy: 0.7110 - loss: 0.6427\n",
      "Epoch 35: val_loss did not improve from 0.63795\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 388ms/step - categorical_accuracy: 0.7111 - loss: 0.6424 - val_categorical_accuracy: 0.7024 - val_loss: 0.6525\n",
      "Epoch 36/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - categorical_accuracy: 0.7169 - loss: 0.6068\n",
      "Epoch 36: val_loss improved from 0.63795 to 0.63408, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 424ms/step - categorical_accuracy: 0.7170 - loss: 0.6067 - val_categorical_accuracy: 0.7265 - val_loss: 0.6341\n",
      "Epoch 37/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - categorical_accuracy: 0.7182 - loss: 0.6021\n",
      "Epoch 37: val_loss improved from 0.63408 to 0.62032, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 405ms/step - categorical_accuracy: 0.7183 - loss: 0.6019 - val_categorical_accuracy: 0.7133 - val_loss: 0.6203\n",
      "Epoch 38/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - categorical_accuracy: 0.7386 - loss: 0.5654\n",
      "Epoch 38: val_loss did not improve from 0.62032\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 443ms/step - categorical_accuracy: 0.7386 - loss: 0.5654 - val_categorical_accuracy: 0.7090 - val_loss: 0.7166\n",
      "Epoch 39/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - categorical_accuracy: 0.7143 - loss: 0.5930\n",
      "Epoch 39: val_loss did not improve from 0.62032\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 442ms/step - categorical_accuracy: 0.7145 - loss: 0.5928 - val_categorical_accuracy: 0.7418 - val_loss: 0.6360\n",
      "Epoch 40/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - categorical_accuracy: 0.7466 - loss: 0.5495\n",
      "Epoch 40: val_loss did not improve from 0.62032\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 410ms/step - categorical_accuracy: 0.7464 - loss: 0.5497 - val_categorical_accuracy: 0.6433 - val_loss: 0.7627\n",
      "Epoch 41/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - categorical_accuracy: 0.7471 - loss: 0.5593\n",
      "Epoch 41: val_loss did not improve from 0.62032\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 422ms/step - categorical_accuracy: 0.7469 - loss: 0.5594 - val_categorical_accuracy: 0.6105 - val_loss: 0.8898\n",
      "Epoch 42/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - categorical_accuracy: 0.7417 - loss: 0.5509\n",
      "Epoch 42: val_loss improved from 0.62032 to 0.60057, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 421ms/step - categorical_accuracy: 0.7417 - loss: 0.5510 - val_categorical_accuracy: 0.7221 - val_loss: 0.6006\n",
      "Epoch 43/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - categorical_accuracy: 0.7572 - loss: 0.5234\n",
      "Epoch 43: val_loss did not improve from 0.60057\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 416ms/step - categorical_accuracy: 0.7571 - loss: 0.5237 - val_categorical_accuracy: 0.6586 - val_loss: 0.8791\n",
      "Epoch 44/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step - categorical_accuracy: 0.7273 - loss: 0.5692\n",
      "Epoch 44: val_loss improved from 0.60057 to 0.59436, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 480ms/step - categorical_accuracy: 0.7274 - loss: 0.5691 - val_categorical_accuracy: 0.7133 - val_loss: 0.5944\n",
      "Epoch 45/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - categorical_accuracy: 0.7493 - loss: 0.5368\n",
      "Epoch 45: val_loss did not improve from 0.59436\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 423ms/step - categorical_accuracy: 0.7492 - loss: 0.5369 - val_categorical_accuracy: 0.6346 - val_loss: 0.7936\n",
      "Epoch 46/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - categorical_accuracy: 0.7410 - loss: 0.5514\n",
      "Epoch 46: val_loss did not improve from 0.59436\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 435ms/step - categorical_accuracy: 0.7410 - loss: 0.5515 - val_categorical_accuracy: 0.6652 - val_loss: 0.7245\n",
      "Epoch 47/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - categorical_accuracy: 0.7589 - loss: 0.5444\n",
      "Epoch 47: val_loss did not improve from 0.59436\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 426ms/step - categorical_accuracy: 0.7589 - loss: 0.5444 - val_categorical_accuracy: 0.6740 - val_loss: 0.7321\n",
      "Epoch 48/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - categorical_accuracy: 0.7609 - loss: 0.5203\n",
      "Epoch 48: val_loss did not improve from 0.59436\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 400ms/step - categorical_accuracy: 0.7609 - loss: 0.5203 - val_categorical_accuracy: 0.7265 - val_loss: 0.6073\n",
      "Epoch 49/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - categorical_accuracy: 0.7631 - loss: 0.5405\n",
      "Epoch 49: val_loss did not improve from 0.59436\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 416ms/step - categorical_accuracy: 0.7631 - loss: 0.5404 - val_categorical_accuracy: 0.6805 - val_loss: 0.6510\n",
      "Epoch 50/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - categorical_accuracy: 0.7438 - loss: 0.5384\n",
      "Epoch 50: val_loss did not improve from 0.59436\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 416ms/step - categorical_accuracy: 0.7438 - loss: 0.5384 - val_categorical_accuracy: 0.7309 - val_loss: 0.6052\n",
      "Epoch 51/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - categorical_accuracy: 0.7706 - loss: 0.5142\n",
      "Epoch 51: val_loss did not improve from 0.59436\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 420ms/step - categorical_accuracy: 0.7705 - loss: 0.5143 - val_categorical_accuracy: 0.7068 - val_loss: 0.6262\n",
      "Epoch 52/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - categorical_accuracy: 0.7575 - loss: 0.5162\n",
      "Epoch 52: val_loss improved from 0.59436 to 0.57832, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 415ms/step - categorical_accuracy: 0.7575 - loss: 0.5161 - val_categorical_accuracy: 0.7505 - val_loss: 0.5783\n",
      "Epoch 53/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - categorical_accuracy: 0.7560 - loss: 0.5314\n",
      "Epoch 53: val_loss did not improve from 0.57832\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 414ms/step - categorical_accuracy: 0.7561 - loss: 0.5313 - val_categorical_accuracy: 0.6674 - val_loss: 0.6883\n",
      "Epoch 54/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - categorical_accuracy: 0.7794 - loss: 0.4906\n",
      "Epoch 54: val_loss did not improve from 0.57832\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 414ms/step - categorical_accuracy: 0.7794 - loss: 0.4908 - val_categorical_accuracy: 0.6937 - val_loss: 0.7024\n",
      "Epoch 55/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - categorical_accuracy: 0.7512 - loss: 0.5530\n",
      "Epoch 55: val_loss did not improve from 0.57832\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 410ms/step - categorical_accuracy: 0.7513 - loss: 0.5528 - val_categorical_accuracy: 0.7177 - val_loss: 0.6465\n",
      "Epoch 56/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - categorical_accuracy: 0.7882 - loss: 0.4912\n",
      "Epoch 56: val_loss did not improve from 0.57832\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 415ms/step - categorical_accuracy: 0.7880 - loss: 0.4913 - val_categorical_accuracy: 0.6871 - val_loss: 0.7117\n",
      "Epoch 57/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - categorical_accuracy: 0.7460 - loss: 0.5566\n",
      "Epoch 57: val_loss did not improve from 0.57832\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 410ms/step - categorical_accuracy: 0.7461 - loss: 0.5564 - val_categorical_accuracy: 0.6674 - val_loss: 0.7024\n",
      "Epoch 58/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - categorical_accuracy: 0.7850 - loss: 0.4873\n",
      "Epoch 58: val_loss did not improve from 0.57832\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 415ms/step - categorical_accuracy: 0.7849 - loss: 0.4874 - val_categorical_accuracy: 0.7068 - val_loss: 0.6646\n",
      "Epoch 59/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - categorical_accuracy: 0.7567 - loss: 0.5082\n",
      "Epoch 59: val_loss improved from 0.57832 to 0.55042, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 421ms/step - categorical_accuracy: 0.7568 - loss: 0.5080 - val_categorical_accuracy: 0.7593 - val_loss: 0.5504\n",
      "Epoch 60/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - categorical_accuracy: 0.7757 - loss: 0.4796\n",
      "Epoch 60: val_loss did not improve from 0.55042\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 423ms/step - categorical_accuracy: 0.7756 - loss: 0.4798 - val_categorical_accuracy: 0.6149 - val_loss: 1.0446\n",
      "Epoch 61/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - categorical_accuracy: 0.7733 - loss: 0.4879\n",
      "Epoch 61: val_loss did not improve from 0.55042\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 420ms/step - categorical_accuracy: 0.7733 - loss: 0.4878 - val_categorical_accuracy: 0.7112 - val_loss: 0.6150\n",
      "Epoch 62/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - categorical_accuracy: 0.7818 - loss: 0.5019\n",
      "Epoch 62: val_loss did not improve from 0.55042\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 418ms/step - categorical_accuracy: 0.7818 - loss: 0.5019 - val_categorical_accuracy: 0.7265 - val_loss: 0.6433\n",
      "Epoch 63/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - categorical_accuracy: 0.7403 - loss: 0.5048\n",
      "Epoch 63: val_loss did not improve from 0.55042\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 423ms/step - categorical_accuracy: 0.7404 - loss: 0.5047 - val_categorical_accuracy: 0.6346 - val_loss: 0.8316\n",
      "Epoch 64/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - categorical_accuracy: 0.7566 - loss: 0.5145\n",
      "Epoch 64: val_loss improved from 0.55042 to 0.54468, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 420ms/step - categorical_accuracy: 0.7567 - loss: 0.5145 - val_categorical_accuracy: 0.7877 - val_loss: 0.5447\n",
      "Epoch 65/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - categorical_accuracy: 0.7711 - loss: 0.4935\n",
      "Epoch 65: val_loss did not improve from 0.54468\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 414ms/step - categorical_accuracy: 0.7711 - loss: 0.4935 - val_categorical_accuracy: 0.7549 - val_loss: 0.5549\n",
      "Epoch 66/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - categorical_accuracy: 0.7590 - loss: 0.5088\n",
      "Epoch 66: val_loss did not improve from 0.54468\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 415ms/step - categorical_accuracy: 0.7591 - loss: 0.5087 - val_categorical_accuracy: 0.6411 - val_loss: 0.8425\n",
      "Epoch 67/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - categorical_accuracy: 0.7964 - loss: 0.4544\n",
      "Epoch 67: val_loss did not improve from 0.54468\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 422ms/step - categorical_accuracy: 0.7964 - loss: 0.4544 - val_categorical_accuracy: 0.7746 - val_loss: 0.5530\n",
      "Epoch 68/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - categorical_accuracy: 0.7871 - loss: 0.4436\n",
      "Epoch 68: val_loss did not improve from 0.54468\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 420ms/step - categorical_accuracy: 0.7872 - loss: 0.4435 - val_categorical_accuracy: 0.6980 - val_loss: 0.6555\n",
      "Epoch 69/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - categorical_accuracy: 0.7842 - loss: 0.4699\n",
      "Epoch 69: val_loss did not improve from 0.54468\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 413ms/step - categorical_accuracy: 0.7842 - loss: 0.4698 - val_categorical_accuracy: 0.7396 - val_loss: 0.5881\n",
      "Epoch 70/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - categorical_accuracy: 0.8035 - loss: 0.4498\n",
      "Epoch 70: val_loss did not improve from 0.54468\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 411ms/step - categorical_accuracy: 0.8035 - loss: 0.4499 - val_categorical_accuracy: 0.7702 - val_loss: 0.5456\n",
      "Epoch 71/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - categorical_accuracy: 0.7970 - loss: 0.4576\n",
      "Epoch 71: val_loss did not improve from 0.54468\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 418ms/step - categorical_accuracy: 0.7970 - loss: 0.4576 - val_categorical_accuracy: 0.7068 - val_loss: 0.7417\n",
      "Epoch 72/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - categorical_accuracy: 0.7887 - loss: 0.4554\n",
      "Epoch 72: val_loss improved from 0.54468 to 0.50342, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 421ms/step - categorical_accuracy: 0.7887 - loss: 0.4554 - val_categorical_accuracy: 0.7768 - val_loss: 0.5034\n",
      "Epoch 73/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - categorical_accuracy: 0.8065 - loss: 0.4396\n",
      "Epoch 73: val_loss did not improve from 0.50342\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 406ms/step - categorical_accuracy: 0.8064 - loss: 0.4398 - val_categorical_accuracy: 0.7396 - val_loss: 0.6316\n",
      "Epoch 74/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - categorical_accuracy: 0.8103 - loss: 0.4339\n",
      "Epoch 74: val_loss did not improve from 0.50342\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 421ms/step - categorical_accuracy: 0.8102 - loss: 0.4338 - val_categorical_accuracy: 0.7177 - val_loss: 0.6712\n",
      "Epoch 75/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - categorical_accuracy: 0.7900 - loss: 0.4450\n",
      "Epoch 75: val_loss did not improve from 0.50342\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 456ms/step - categorical_accuracy: 0.7901 - loss: 0.4449 - val_categorical_accuracy: 0.7659 - val_loss: 0.5208\n",
      "Epoch 76/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - categorical_accuracy: 0.8094 - loss: 0.4119\n",
      "Epoch 76: val_loss did not improve from 0.50342\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 439ms/step - categorical_accuracy: 0.8094 - loss: 0.4119 - val_categorical_accuracy: 0.7724 - val_loss: 0.5135\n",
      "Epoch 77/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - categorical_accuracy: 0.8154 - loss: 0.3860\n",
      "Epoch 77: val_loss did not improve from 0.50342\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 433ms/step - categorical_accuracy: 0.8153 - loss: 0.3863 - val_categorical_accuracy: 0.7374 - val_loss: 0.6069\n",
      "Epoch 78/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - categorical_accuracy: 0.7699 - loss: 0.4721\n",
      "Epoch 78: val_loss improved from 0.50342 to 0.49535, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 452ms/step - categorical_accuracy: 0.7701 - loss: 0.4718 - val_categorical_accuracy: 0.7790 - val_loss: 0.4954\n",
      "Epoch 79/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - categorical_accuracy: 0.8064 - loss: 0.4281\n",
      "Epoch 79: val_loss did not improve from 0.49535\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 434ms/step - categorical_accuracy: 0.8063 - loss: 0.4281 - val_categorical_accuracy: 0.7746 - val_loss: 0.5455\n",
      "Epoch 80/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - categorical_accuracy: 0.8041 - loss: 0.4278\n",
      "Epoch 80: val_loss did not improve from 0.49535\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 426ms/step - categorical_accuracy: 0.8041 - loss: 0.4279 - val_categorical_accuracy: 0.6937 - val_loss: 0.7531\n",
      "Epoch 81/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - categorical_accuracy: 0.8363 - loss: 0.3852\n",
      "Epoch 81: val_loss did not improve from 0.49535\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 428ms/step - categorical_accuracy: 0.8362 - loss: 0.3853 - val_categorical_accuracy: 0.7090 - val_loss: 0.6902\n",
      "Epoch 82/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - categorical_accuracy: 0.7896 - loss: 0.4634\n",
      "Epoch 82: val_loss did not improve from 0.49535\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 427ms/step - categorical_accuracy: 0.7897 - loss: 0.4631 - val_categorical_accuracy: 0.7615 - val_loss: 0.5449\n",
      "Epoch 83/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401ms/step - categorical_accuracy: 0.8173 - loss: 0.3984\n",
      "Epoch 83: val_loss improved from 0.49535 to 0.49245, saving model to model/model_transferlearning_aug.keras\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 425ms/step - categorical_accuracy: 0.8173 - loss: 0.3985 - val_categorical_accuracy: 0.7943 - val_loss: 0.4925\n",
      "Epoch 84/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - categorical_accuracy: 0.8169 - loss: 0.4043\n",
      "Epoch 84: val_loss did not improve from 0.49245\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 418ms/step - categorical_accuracy: 0.8168 - loss: 0.4045 - val_categorical_accuracy: 0.7702 - val_loss: 0.5446\n",
      "Epoch 85/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - categorical_accuracy: 0.8121 - loss: 0.4004\n",
      "Epoch 85: val_loss did not improve from 0.49245\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 412ms/step - categorical_accuracy: 0.8121 - loss: 0.4005 - val_categorical_accuracy: 0.7418 - val_loss: 0.5655\n",
      "Epoch 86/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - categorical_accuracy: 0.8008 - loss: 0.4254\n",
      "Epoch 86: val_loss did not improve from 0.49245\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 426ms/step - categorical_accuracy: 0.8008 - loss: 0.4254 - val_categorical_accuracy: 0.6871 - val_loss: 0.6700\n",
      "Epoch 87/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - categorical_accuracy: 0.8049 - loss: 0.4258\n",
      "Epoch 87: val_loss did not improve from 0.49245\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 416ms/step - categorical_accuracy: 0.8049 - loss: 0.4257 - val_categorical_accuracy: 0.7133 - val_loss: 0.7167\n",
      "Epoch 88/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - categorical_accuracy: 0.8233 - loss: 0.3997\n",
      "Epoch 88: val_loss did not improve from 0.49245\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 418ms/step - categorical_accuracy: 0.8233 - loss: 0.3997 - val_categorical_accuracy: 0.7484 - val_loss: 0.5722\n",
      "Epoch 89/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - categorical_accuracy: 0.8116 - loss: 0.4327\n",
      "Epoch 89: val_loss did not improve from 0.49245\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 416ms/step - categorical_accuracy: 0.8116 - loss: 0.4325 - val_categorical_accuracy: 0.7265 - val_loss: 0.6397\n",
      "Epoch 90/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - categorical_accuracy: 0.8283 - loss: 0.4129\n",
      "Epoch 90: val_loss did not improve from 0.49245\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 409ms/step - categorical_accuracy: 0.8283 - loss: 0.4128 - val_categorical_accuracy: 0.7418 - val_loss: 0.5502\n",
      "Epoch 91/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - categorical_accuracy: 0.8305 - loss: 0.3912\n",
      "Epoch 91: val_loss did not improve from 0.49245\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 403ms/step - categorical_accuracy: 0.8305 - loss: 0.3912 - val_categorical_accuracy: 0.7571 - val_loss: 0.5978\n",
      "Epoch 92/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - categorical_accuracy: 0.8139 - loss: 0.4136\n",
      "Epoch 92: val_loss did not improve from 0.49245\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 399ms/step - categorical_accuracy: 0.8139 - loss: 0.4136 - val_categorical_accuracy: 0.6827 - val_loss: 0.7243\n",
      "Epoch 93/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - categorical_accuracy: 0.8230 - loss: 0.3900\n",
      "Epoch 93: val_loss did not improve from 0.49245\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 400ms/step - categorical_accuracy: 0.8230 - loss: 0.3901 - val_categorical_accuracy: 0.7637 - val_loss: 0.5837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16970ea50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "STEPS_PER_EPOCH=len(x_train)/BATCH_SIZE\n",
    "\n",
    "transfer_model.fit(train_dataset,steps_per_epoch=int(STEPS_PER_EPOCH),epochs=EPOCHS,\n",
    "          validation_data=val_dataset,validation_steps=None,\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "{'categorical_accuracy': 0.8023715615272522, 'loss': 0.4625433087348938}\n"
     ]
    }
   ],
   "source": [
    "# load the best model, trained before\n",
    "model = keras.models.load_model(\"model/model_transferlearning_aug.keras\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# evaluates with the test_dataset\n",
    "print(model.evaluate(test_dataset, verbose=0,return_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 22:52:58.850256: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "class_names = {0: 'No Diabetic or Hipertensive Retinopathy', 1: 'Diabetic Retinopathy', 2: 'Hipertensive Retinopathy'}\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "y_proba = []\n",
    "\n",
    "# iterate over the batch\n",
    "for x_batch, y_batch in test_dataset:\n",
    "    \n",
    "    # prediction of the model\n",
    "    y_test_proba = transfer_model.predict(x_batch)\n",
    "\n",
    "    # convert into the most likely class\n",
    "    y_pred.extend(np.argmax(y_test_proba, axis=1))\n",
    "    y_proba.extend(y_test_proba)\n",
    "\n",
    "    # convert the true list into a value for this x\n",
    "    y_true.extend(np.argmax(y_batch.numpy(), axis=1))\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "# numerical values to strings\n",
    "y_pred_names = [class_names[label] for label in y_pred]\n",
    "y_true_names = [class_names[label] for label in y_true]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix and Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      " [[66  1  7]\n",
      " [ 9 50 11]\n",
      " [13  9 87]]\n",
      "\n",
      "Classification Report:\n",
      "                                          precision    recall  f1-score   support\n",
      "\n",
      "                   Diabetic Retinopathy       0.83      0.71      0.77        70\n",
      "               Hipertensive Retinopathy       0.83      0.80      0.81       109\n",
      "No Diabetic or Hipertensive Retinopathy       0.75      0.89      0.81        74\n",
      "\n",
      "                               accuracy                           0.80       253\n",
      "                              macro avg       0.80      0.80      0.80       253\n",
      "                           weighted avg       0.81      0.80      0.80       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true_names, y_pred_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-Averaged ROC-AUC Score: 0.9367\n"
     ]
    }
   ],
   "source": [
    "# do one-hot enconding\n",
    "y_true_one_hot = tf.keras.utils.to_categorical(y_true, num_classes=3)\n",
    "\n",
    "y_proba = np.array(y_proba)  \n",
    "\n",
    "# ROC-AUC score for each class\n",
    "auc = roc_auc_score(y_true_one_hot, y_proba, average='macro', multi_class='ovr')\n",
    "\n",
    "print(f\"Macro-Averaged ROC-AUC Score: {auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
